{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "from preprocess import get_mnist, get_webcam\n",
    "from train import TrainerVaDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size = 128\n",
    "    lr = 1e-5\n",
    "    dataset = 'webcam'\n",
    "    pretrain = True\n",
    "    epochs = 200\n",
    "    n_shots = 10\n",
    "    sup_mul = 0.9\n",
    "    cl_mul = 100\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    \n",
    "args = Args() # Parsing all the arguments for the training\n",
    "if args.dataset == 'mnist':\n",
    "    dataloader_sup, dataloader_unsup, dataloader_test = get_mnist(args)\n",
    "    n_classes = 10\n",
    "else:\n",
    "    dataloader_sup, dataloader_unsup, dataloader_test = get_webcam(args)\n",
    "    n_classes = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vade = TrainerVaDE(args, device, dataloader_sup, dataloader_unsup, dataloader_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == 'webcam':\n",
    "    classes = ['back_pack',\n",
    "                'bike',\n",
    "                'bike_helmet',\n",
    "                'bookcase',\n",
    "                'bottle',\n",
    "                'calculator',\n",
    "                'desk_chair',\n",
    "                'desk_lamp',\n",
    "                'desktop_computer',\n",
    "                'file_cabinet',\n",
    "                'headphones',\n",
    "                'keyboard',\n",
    "                'laptop_computer',\n",
    "                'letter_tray',\n",
    "                'mobile_phone',\n",
    "                'monitor',\n",
    "                'mouse',\n",
    "                'mug',\n",
    "                'paper_notebook',\n",
    "                'pen',\n",
    "                'phone',\n",
    "                'printer',\n",
    "                'projector',\n",
    "                'punchers',\n",
    "                'ring_binder',\n",
    "                'ruler',\n",
    "                'scissors',\n",
    "                'speaker',\n",
    "                'stapler',\n",
    "                'tape_dispenser',\n",
    "                'trash_can']\n",
    "else:\n",
    "    classes = ['0',\n",
    "               '1',\n",
    "               '2',\n",
    "               '3',\n",
    "               '4',\n",
    "               '5',\n",
    "               '6',\n",
    "               '7',\n",
    "               '8',\n",
    "               '9']\n",
    "\n",
    "\n",
    "def get_latent_space(dataloader, z_dim, model, device, ftr_ext=None):\n",
    "    z = torch.zeros((1, z_dim)).float().to(device)\n",
    "    y = torch.zeros((1)).long().to(device)\n",
    "    with torch.no_grad():\n",
    "        for img, label in dataloader:\n",
    "            img, label = img.to(device).float(), label.to(device).long()\n",
    "            if ftr_ext is not None:\n",
    "                img = ftr_ext(img); img = img.detach()\n",
    "\n",
    "            mu, log_var = model.encode(img)\n",
    "            z_l = model.reparameterize(mu, log_var)\n",
    "            y = torch.cat((y, label), dim=0)\n",
    "            z = torch.cat((z, z_l), dim=0)\n",
    "    return z[1:], y[1:]\n",
    "\n",
    "\n",
    "def plot_tsne(X_embedded, y, ticks, dataset):\n",
    "    f, ax1 = plt.subplots(1, 1, sharey=True, figsize=(15,10))\n",
    "\n",
    "    cmap = plt.get_cmap('jet', 31)\n",
    "\n",
    "\n",
    "    cax = ax1.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y.numpy(),\n",
    "                      s=15, cmap=cmap)\n",
    "\n",
    "    cbar = f.colorbar(cax, ticks=np.linspace(0,30,31))\n",
    "    cbar.ax.set_yticklabels(ticks)\n",
    "\n",
    "    ax1.xaxis.set_visible(False)\n",
    "    ax1.yaxis.set_visible(False)\n",
    "    plt.savefig('weights/vade_tsne_{}_ss.png'.format(dataset))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VaDE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing VaDE... Epoch: -1, Loss: 21.04513692855835, Acc: 73.26345915841584\n",
      "Training VaDE... Epoch: 0, Loss: 4065.2872314453125, Acc: 70.0\n",
      "Testing VaDE... Epoch: 0, Loss: 21.212724685668945, Acc: 74.20134591584159\n",
      "Training VaDE... Epoch: 1, Loss: 4009.570556640625, Acc: 70.64516129032258\n",
      "Testing VaDE... Epoch: 1, Loss: 21.345197200775146, Acc: 73.70629641089108\n",
      "Training VaDE... Epoch: 2, Loss: 3963.1649169921875, Acc: 69.6774193548387\n",
      "Testing VaDE... Epoch: 2, Loss: 21.65846872329712, Acc: 74.09692141089108\n",
      "Training VaDE... Epoch: 3, Loss: 3910.8416748046875, Acc: 73.87096774193549\n",
      "Testing VaDE... Epoch: 3, Loss: 21.803311824798584, Acc: 73.02947091584159\n",
      "Training VaDE... Epoch: 4, Loss: 3863.6785888671875, Acc: 74.51612903225806\n",
      "Testing VaDE... Epoch: 4, Loss: 22.179669857025146, Acc: 72.92504641089108\n",
      "Training VaDE... Epoch: 5, Loss: 3814.556640625, Acc: 70.96774193548387\n",
      "Testing VaDE... Epoch: 5, Loss: 22.33392906188965, Acc: 73.26345915841584\n",
      "Training VaDE... Epoch: 6, Loss: 3757.980224609375, Acc: 73.22580645161291\n",
      "Testing VaDE... Epoch: 6, Loss: 22.55504560470581, Acc: 75.08702042079207\n",
      "Training VaDE... Epoch: 7, Loss: 3715.3809814453125, Acc: 71.93548387096774\n",
      "Testing VaDE... Epoch: 7, Loss: 22.883000373840332, Acc: 73.51098391089108\n",
      "Training VaDE... Epoch: 8, Loss: 3662.740966796875, Acc: 73.54838709677419\n",
      "Testing VaDE... Epoch: 8, Loss: 23.123851776123047, Acc: 72.8206219059406\n",
      "Training VaDE... Epoch: 9, Loss: 3619.3251953125, Acc: 71.93548387096774\n",
      "Testing VaDE... Epoch: 9, Loss: 23.357481956481934, Acc: 72.58663366336634\n",
      "Training VaDE... Epoch: 10, Loss: 3578.7672119140625, Acc: 69.35483870967742\n",
      "Testing VaDE... Epoch: 10, Loss: 23.583401679992676, Acc: 74.53975866336634\n",
      "Training VaDE... Epoch: 11, Loss: 3535.4696044921875, Acc: 71.61290322580646\n",
      "Testing VaDE... Epoch: 11, Loss: 23.809795379638672, Acc: 73.45877165841584\n",
      "Training VaDE... Epoch: 12, Loss: 3494.469970703125, Acc: 71.93548387096774\n",
      "Testing VaDE... Epoch: 12, Loss: 24.09666156768799, Acc: 72.48220915841584\n",
      "Training VaDE... Epoch: 13, Loss: 3463.4183349609375, Acc: 66.77419354838709\n",
      "Testing VaDE... Epoch: 13, Loss: 24.424971103668213, Acc: 74.00603341584159\n",
      "Training VaDE... Epoch: 14, Loss: 3420.57421875, Acc: 69.03225806451613\n",
      "Testing VaDE... Epoch: 14, Loss: 24.691051959991455, Acc: 73.6927599009901\n",
      "Training VaDE... Epoch: 15, Loss: 3375.7423095703125, Acc: 72.58064516129032\n",
      "Testing VaDE... Epoch: 15, Loss: 24.950944423675537, Acc: 72.87283415841584\n",
      "Training VaDE... Epoch: 16, Loss: 3335.238037109375, Acc: 70.96774193548387\n",
      "Testing VaDE... Epoch: 16, Loss: 25.113868713378906, Acc: 72.14379641089108\n",
      "Training VaDE... Epoch: 17, Loss: 3315.031494140625, Acc: 65.16129032258064\n",
      "Testing VaDE... Epoch: 17, Loss: 25.362706184387207, Acc: 72.4299969059406\n",
      "Training VaDE... Epoch: 18, Loss: 3278.4552001953125, Acc: 66.77419354838709\n",
      "Testing VaDE... Epoch: 18, Loss: 25.693254947662354, Acc: 71.98715965346534\n",
      "Training VaDE... Epoch: 19, Loss: 3244.8756103515625, Acc: 66.77419354838709\n",
      "Testing VaDE... Epoch: 19, Loss: 26.062969207763672, Acc: 70.72439665841584\n",
      "Training VaDE... Epoch: 20, Loss: 3206.8759765625, Acc: 63.87096774193548\n",
      "Testing VaDE... Epoch: 20, Loss: 26.239899158477783, Acc: 71.55785891089108\n",
      "Training VaDE... Epoch: 21, Loss: 3187.1514892578125, Acc: 68.06451612903226\n",
      "Testing VaDE... Epoch: 21, Loss: 26.60649871826172, Acc: 70.42465965346534\n",
      "Training VaDE... Epoch: 22, Loss: 3150.3121337890625, Acc: 66.45161290322581\n",
      "Testing VaDE... Epoch: 22, Loss: 26.804282188415527, Acc: 71.2581219059406\n",
      "Training VaDE... Epoch: 23, Loss: 3123.3658447265625, Acc: 65.48387096774194\n",
      "Testing VaDE... Epoch: 23, Loss: 27.04490566253662, Acc: 70.91970915841584\n",
      "Training VaDE... Epoch: 24, Loss: 3085.38037109375, Acc: 65.16129032258064\n",
      "Testing VaDE... Epoch: 24, Loss: 27.2734956741333, Acc: 70.58129641089108\n",
      "Training VaDE... Epoch: 25, Loss: 3067.374755859375, Acc: 65.16129032258064\n",
      "Testing VaDE... Epoch: 25, Loss: 27.486899375915527, Acc: 69.0052599009901\n",
      "Training VaDE... Epoch: 26, Loss: 3046.4757080078125, Acc: 63.54838709677419\n",
      "Testing VaDE... Epoch: 26, Loss: 28.009185791015625, Acc: 68.47153465346534\n",
      "Training VaDE... Epoch: 27, Loss: 3025.343505859375, Acc: 63.87096774193548\n",
      "Testing VaDE... Epoch: 27, Loss: 28.144841194152832, Acc: 68.95304764851485\n",
      "Training VaDE... Epoch: 28, Loss: 2999.427734375, Acc: 64.19354838709678\n",
      "Testing VaDE... Epoch: 28, Loss: 28.525134086608887, Acc: 68.08090965346534\n",
      "Training VaDE... Epoch: 29, Loss: 2972.6055908203125, Acc: 67.74193548387096\n",
      "Testing VaDE... Epoch: 29, Loss: 28.879618167877197, Acc: 68.8099474009901\n",
      "Training VaDE... Epoch: 30, Loss: 2947.8951416015625, Acc: 62.903225806451616\n",
      "Testing VaDE... Epoch: 30, Loss: 29.036252975463867, Acc: 66.60929764851485\n",
      "Training VaDE... Epoch: 31, Loss: 2937.285400390625, Acc: 62.25806451612903\n",
      "Testing VaDE... Epoch: 31, Loss: 29.41126251220703, Acc: 65.63273514851485\n",
      "Training VaDE... Epoch: 32, Loss: 2917.1148681640625, Acc: 66.12903225806451\n",
      "Testing VaDE... Epoch: 32, Loss: 29.616116523742676, Acc: 67.78117264851485\n",
      "Training VaDE... Epoch: 33, Loss: 2904.502197265625, Acc: 60.322580645161295\n",
      "Testing VaDE... Epoch: 33, Loss: 30.130715370178223, Acc: 67.29965965346534\n",
      "Training VaDE... Epoch: 34, Loss: 2890.2041015625, Acc: 60.322580645161295\n",
      "Testing VaDE... Epoch: 34, Loss: 30.264702320098877, Acc: 66.3753094059406\n",
      "Training VaDE... Epoch: 35, Loss: 2874.654541015625, Acc: 64.19354838709678\n",
      "Testing VaDE... Epoch: 35, Loss: 30.25485134124756, Acc: 65.13768564356435\n",
      "Training VaDE... Epoch: 36, Loss: 2858.075439453125, Acc: 64.19354838709678\n",
      "Testing VaDE... Epoch: 36, Loss: 30.70391273498535, Acc: 65.08547339108911\n",
      "Training VaDE... Epoch: 37, Loss: 2853.1121826171875, Acc: 62.58064516129033\n",
      "Testing VaDE... Epoch: 37, Loss: 31.19828224182129, Acc: 65.24211014851485\n",
      "Training VaDE... Epoch: 38, Loss: 2828.0994873046875, Acc: 58.70967741935483\n",
      "Testing VaDE... Epoch: 38, Loss: 31.492851734161377, Acc: 62.74172339108911\n",
      "Training VaDE... Epoch: 39, Loss: 2821.4925537109375, Acc: 62.25806451612903\n",
      "Testing VaDE... Epoch: 39, Loss: 31.639163494110107, Acc: 63.08013613861387\n",
      "Training VaDE... Epoch: 40, Loss: 2813.1055908203125, Acc: 60.0\n",
      "Testing VaDE... Epoch: 40, Loss: 31.822476863861084, Acc: 63.52297339108911\n",
      "Training VaDE... Epoch: 41, Loss: 2797.6005859375, Acc: 59.354838709677416\n",
      "Testing VaDE... Epoch: 41, Loss: 32.25603914260864, Acc: 62.49419863861387\n",
      "Training VaDE... Epoch: 42, Loss: 2800.0916748046875, Acc: 59.354838709677416\n",
      "Testing VaDE... Epoch: 42, Loss: 32.16807794570923, Acc: 63.37987314356435\n",
      "Training VaDE... Epoch: 43, Loss: 2788.58349609375, Acc: 60.0\n",
      "Testing VaDE... Epoch: 43, Loss: 32.59385108947754, Acc: 60.684173886138616\n",
      "Training VaDE... Epoch: 44, Loss: 2768.0665283203125, Acc: 56.774193548387096\n",
      "Testing VaDE... Epoch: 44, Loss: 32.78239917755127, Acc: 62.40331064356435\n",
      "Training VaDE... Epoch: 45, Loss: 2766.6290283203125, Acc: 56.774193548387096\n",
      "Testing VaDE... Epoch: 45, Loss: 33.10010814666748, Acc: 59.916460396039604\n",
      "Training VaDE... Epoch: 46, Loss: 2755.60009765625, Acc: 57.096774193548384\n",
      "Testing VaDE... Epoch: 46, Loss: 33.07688236236572, Acc: 60.73638613861387\n",
      "Training VaDE... Epoch: 47, Loss: 2744.8604736328125, Acc: 59.354838709677416\n",
      "Testing VaDE... Epoch: 47, Loss: 33.164610862731934, Acc: 59.21256188118812\n",
      "Training VaDE... Epoch: 48, Loss: 2741.9757080078125, Acc: 60.322580645161295\n",
      "Testing VaDE... Epoch: 48, Loss: 33.795899391174316, Acc: 59.01724938118812\n",
      "Training VaDE... Epoch: 49, Loss: 2738.17919921875, Acc: 56.451612903225815\n",
      "Testing VaDE... Epoch: 49, Loss: 34.064348220825195, Acc: 58.39263613861387\n",
      "Training VaDE... Epoch: 50, Loss: 2724.5313720703125, Acc: 60.322580645161295\n",
      "Testing VaDE... Epoch: 50, Loss: 34.16923713684082, Acc: 60.307085396039604\n",
      "Training VaDE... Epoch: 51, Loss: 2716.4776611328125, Acc: 58.387096774193544\n",
      "Testing VaDE... Epoch: 51, Loss: 34.4475679397583, Acc: 58.10643564356435\n",
      "Training VaDE... Epoch: 52, Loss: 2720.1002197265625, Acc: 55.80645161290323\n",
      "Testing VaDE... Epoch: 52, Loss: 34.67686080932617, Acc: 57.311649133663366\n",
      "Training VaDE... Epoch: 53, Loss: 2703.8211669921875, Acc: 56.12903225806451\n",
      "Testing VaDE... Epoch: 53, Loss: 34.94358825683594, Acc: 57.116336633663366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VaDE... Epoch: 54, Loss: 2705.3489990234375, Acc: 55.80645161290323\n",
      "Testing VaDE... Epoch: 54, Loss: 35.151594161987305, Acc: 57.80669863861387\n",
      "Training VaDE... Epoch: 55, Loss: 2699.88623046875, Acc: 56.451612903225815\n",
      "Testing VaDE... Epoch: 55, Loss: 35.23458003997803, Acc: 55.64472462871287\n",
      "Training VaDE... Epoch: 56, Loss: 2689.6129150390625, Acc: 57.41935483870968\n",
      "Testing VaDE... Epoch: 56, Loss: 35.367919921875, Acc: 54.91568688118812\n",
      "Training VaDE... Epoch: 57, Loss: 2694.8812255859375, Acc: 54.516129032258064\n",
      "Testing VaDE... Epoch: 57, Loss: 35.786593437194824, Acc: 54.838335396039604\n",
      "Training VaDE... Epoch: 58, Loss: 2671.472900390625, Acc: 51.935483870967744\n",
      "Testing VaDE... Epoch: 58, Loss: 36.06625747680664, Acc: 55.56737314356435\n",
      "Training VaDE... Epoch: 59, Loss: 2682.850830078125, Acc: 55.80645161290323\n",
      "Testing VaDE... Epoch: 59, Loss: 36.06271553039551, Acc: 55.553836633663366\n",
      "Training VaDE... Epoch: 60, Loss: 2681.6112060546875, Acc: 52.903225806451616\n",
      "Testing VaDE... Epoch: 60, Loss: 36.15558052062988, Acc: 53.24876237623762\n",
      "Training VaDE... Epoch: 61, Loss: 2671.7681884765625, Acc: 58.06451612903226\n",
      "Testing VaDE... Epoch: 61, Loss: 36.22163105010986, Acc: 54.13443688118812\n",
      "Training VaDE... Epoch: 62, Loss: 2682.853271484375, Acc: 52.903225806451616\n",
      "Testing VaDE... Epoch: 62, Loss: 36.54369258880615, Acc: 54.66816212871287\n",
      "Training VaDE... Epoch: 63, Loss: 2667.8292236328125, Acc: 50.967741935483865\n",
      "Testing VaDE... Epoch: 63, Loss: 36.61735248565674, Acc: 54.238861386138616\n",
      "Training VaDE... Epoch: 64, Loss: 2662.4820556640625, Acc: 49.354838709677416\n",
      "Testing VaDE... Epoch: 64, Loss: 37.24674892425537, Acc: 51.29563737623762\n",
      "Training VaDE... Epoch: 65, Loss: 2664.151611328125, Acc: 54.516129032258064\n",
      "Testing VaDE... Epoch: 65, Loss: 37.29386901855469, Acc: 54.61594987623762\n",
      "Training VaDE... Epoch: 66, Loss: 2654.3997802734375, Acc: 52.58064516129032\n",
      "Testing VaDE... Epoch: 66, Loss: 37.46993160247803, Acc: 52.46751237623762\n",
      "Training VaDE... Epoch: 67, Loss: 2655.178955078125, Acc: 49.03225806451613\n",
      "Testing VaDE... Epoch: 67, Loss: 37.380550384521484, Acc: 52.27219987623762\n",
      "Training VaDE... Epoch: 68, Loss: 2651.13134765625, Acc: 47.096774193548384\n",
      "Testing VaDE... Epoch: 68, Loss: 37.596309661865234, Acc: 51.79068688118812\n",
      "Training VaDE... Epoch: 69, Loss: 2647.2554931640625, Acc: 51.935483870967744\n",
      "Testing VaDE... Epoch: 69, Loss: 37.55744552612305, Acc: 52.37662438118812\n",
      "Training VaDE... Epoch: 70, Loss: 2631.786865234375, Acc: 48.70967741935484\n",
      "Testing VaDE... Epoch: 70, Loss: 37.90265464782715, Acc: 51.73847462871287\n",
      "Training VaDE... Epoch: 71, Loss: 2641.701416015625, Acc: 48.70967741935484\n",
      "Testing VaDE... Epoch: 71, Loss: 38.13295364379883, Acc: 52.61061262376238\n",
      "Training VaDE... Epoch: 72, Loss: 2635.525634765625, Acc: 50.0\n",
      "Testing VaDE... Epoch: 72, Loss: 38.21125888824463, Acc: 50.61881188118812\n",
      "Training VaDE... Epoch: 73, Loss: 2641.455810546875, Acc: 51.61290322580645\n",
      "Testing VaDE... Epoch: 73, Loss: 38.117302894592285, Acc: 50.671024133663366\n",
      "Training VaDE... Epoch: 74, Loss: 2627.7386474609375, Acc: 46.774193548387096\n",
      "Testing VaDE... Epoch: 74, Loss: 38.551201820373535, Acc: 51.842899133663366\n",
      "Training VaDE... Epoch: 75, Loss: 2637.02392578125, Acc: 49.67741935483871\n",
      "Testing VaDE... Epoch: 75, Loss: 38.44999313354492, Acc: 51.24342512376238\n",
      "Training VaDE... Epoch: 76, Loss: 2623.6407470703125, Acc: 48.70967741935484\n",
      "Testing VaDE... Epoch: 76, Loss: 38.90932273864746, Acc: 49.19941212871287\n",
      "Training VaDE... Epoch: 77, Loss: 2625.62939453125, Acc: 47.096774193548384\n",
      "Testing VaDE... Epoch: 77, Loss: 38.902177810668945, Acc: 50.07155012376238\n",
      "Training VaDE... Epoch: 78, Loss: 2622.8677978515625, Acc: 50.32258064516129\n",
      "Testing VaDE... Epoch: 78, Loss: 39.47493553161621, Acc: 49.62871287128713\n",
      "Training VaDE... Epoch: 79, Loss: 2624.30126953125, Acc: 46.12903225806452\n",
      "Testing VaDE... Epoch: 79, Loss: 39.16422653198242, Acc: 47.72780012376238\n",
      "Training VaDE... Epoch: 80, Loss: 2623.5084228515625, Acc: 47.74193548387097\n",
      "Testing VaDE... Epoch: 80, Loss: 39.538275718688965, Acc: 47.53248762376238\n",
      "Training VaDE... Epoch: 81, Loss: 2619.1583251953125, Acc: 49.03225806451613\n",
      "Testing VaDE... Epoch: 81, Loss: 39.575382232666016, Acc: 46.84212561881188\n",
      "Training VaDE... Epoch: 82, Loss: 2614.9476318359375, Acc: 45.806451612903224\n",
      "Testing VaDE... Epoch: 82, Loss: 39.38744354248047, Acc: 48.17063737623762\n",
      "Training VaDE... Epoch: 83, Loss: 2619.1650390625, Acc: 48.38709677419355\n",
      "Testing VaDE... Epoch: 83, Loss: 39.8374719619751, Acc: 46.80344987623762\n",
      "Training VaDE... Epoch: 84, Loss: 2613.2349853515625, Acc: 44.516129032258064\n",
      "Testing VaDE... Epoch: 84, Loss: 39.83246898651123, Acc: 48.79525061881188\n",
      "Training VaDE... Epoch: 85, Loss: 2610.3577880859375, Acc: 42.25806451612903\n",
      "Testing VaDE... Epoch: 85, Loss: 39.83164024353027, Acc: 46.985225866336634\n",
      "Training VaDE... Epoch: 86, Loss: 2609.889892578125, Acc: 45.483870967741936\n",
      "Testing VaDE... Epoch: 86, Loss: 40.119154930114746, Acc: 44.641475866336634\n",
      "Training VaDE... Epoch: 87, Loss: 2602.0997314453125, Acc: 45.16129032258064\n",
      "Testing VaDE... Epoch: 87, Loss: 40.08940315246582, Acc: 47.33717512376238\n",
      "Training VaDE... Epoch: 88, Loss: 2598.32861328125, Acc: 45.483870967741936\n",
      "Testing VaDE... Epoch: 88, Loss: 40.27546691894531, Acc: 46.84212561881188\n",
      "Training VaDE... Epoch: 89, Loss: 2605.197998046875, Acc: 44.83870967741935\n",
      "Testing VaDE... Epoch: 89, Loss: 40.516098976135254, Acc: 44.94121287128713\n",
      "Training VaDE... Epoch: 90, Loss: 2595.383544921875, Acc: 45.16129032258064\n",
      "Testing VaDE... Epoch: 90, Loss: 40.62546157836914, Acc: 47.58469987623762\n",
      "Training VaDE... Epoch: 91, Loss: 2591.2191162109375, Acc: 45.806451612903224\n",
      "Testing VaDE... Epoch: 91, Loss: 40.77690410614014, Acc: 45.56582611386139\n",
      "Training VaDE... Epoch: 92, Loss: 2600.201416015625, Acc: 44.516129032258064\n",
      "Testing VaDE... Epoch: 92, Loss: 40.83372402191162, Acc: 45.63157487623762\n",
      "Training VaDE... Epoch: 93, Loss: 2592.97314453125, Acc: 42.90322580645161\n",
      "Testing VaDE... Epoch: 93, Loss: 41.22675704956055, Acc: 46.26972462871287\n",
      "Training VaDE... Epoch: 94, Loss: 2593.34423828125, Acc: 45.483870967741936\n",
      "Testing VaDE... Epoch: 94, Loss: 41.17232894897461, Acc: 45.08431311881188\n",
      "Training VaDE... Epoch: 95, Loss: 2584.94775390625, Acc: 50.0\n",
      "Testing VaDE... Epoch: 95, Loss: 41.56059646606445, Acc: 41.80267636138614\n",
      "Training VaDE... Epoch: 96, Loss: 2579.3817138671875, Acc: 40.96774193548387\n",
      "Testing VaDE... Epoch: 96, Loss: 41.55498027801514, Acc: 44.250850866336634\n",
      "Training VaDE... Epoch: 97, Loss: 2577.666259765625, Acc: 43.54838709677419\n",
      "Testing VaDE... Epoch: 97, Loss: 41.288546562194824, Acc: 45.33183787128713\n",
      "Training VaDE... Epoch: 98, Loss: 2577.4151611328125, Acc: 42.90322580645161\n",
      "Testing VaDE... Epoch: 98, Loss: 41.74706840515137, Acc: 42.15462561881188\n",
      "Training VaDE... Epoch: 99, Loss: 2580.00146484375, Acc: 43.54838709677419\n",
      "Testing VaDE... Epoch: 99, Loss: 41.69150447845459, Acc: 44.69368811881188\n",
      "Training VaDE... Epoch: 100, Loss: 2588.2421875, Acc: 43.54838709677419\n",
      "Testing VaDE... Epoch: 100, Loss: 41.878211975097656, Acc: 43.50827660891089\n",
      "Training VaDE... Epoch: 101, Loss: 2586.1534423828125, Acc: 44.516129032258064\n",
      "Testing VaDE... Epoch: 101, Loss: 41.66535186767578, Acc: 43.71712561881188\n",
      "Training VaDE... Epoch: 102, Loss: 2577.794921875, Acc: 42.90322580645161\n",
      "Testing VaDE... Epoch: 102, Loss: 42.12614059448242, Acc: 43.13118811881188\n",
      "Training VaDE... Epoch: 103, Loss: 2568.755615234375, Acc: 42.25806451612903\n",
      "Testing VaDE... Epoch: 103, Loss: 42.083909034729004, Acc: 42.58392636138614\n",
      "Training VaDE... Epoch: 104, Loss: 2584.734375, Acc: 42.58064516129032\n",
      "Testing VaDE... Epoch: 104, Loss: 42.337289810180664, Acc: 42.44082611386139\n",
      "Training VaDE... Epoch: 105, Loss: 2568.9771728515625, Acc: 42.90322580645161\n",
      "Testing VaDE... Epoch: 105, Loss: 42.517526626586914, Acc: 42.231977103960396\n",
      "Training VaDE... Epoch: 106, Loss: 2586.9754638671875, Acc: 40.64516129032258\n",
      "Testing VaDE... Epoch: 106, Loss: 42.55053997039795, Acc: 41.5416150990099\n",
      "Training VaDE... Epoch: 107, Loss: 2568.499267578125, Acc: 44.83870967741935\n",
      "Testing VaDE... Epoch: 107, Loss: 42.58410930633545, Acc: 43.02676361386139\n",
      "Training VaDE... Epoch: 108, Loss: 2567.533935546875, Acc: 42.25806451612903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing VaDE... Epoch: 108, Loss: 42.56789779663086, Acc: 43.32650061881188\n",
      "Training VaDE... Epoch: 109, Loss: 2553.79736328125, Acc: 47.41935483870968\n",
      "Testing VaDE... Epoch: 109, Loss: 42.694539070129395, Acc: 41.80267636138614\n",
      "Training VaDE... Epoch: 110, Loss: 2568.9383544921875, Acc: 37.41935483870968\n",
      "Testing VaDE... Epoch: 110, Loss: 42.65861892700195, Acc: 41.62090037128713\n",
      "Training VaDE... Epoch: 111, Loss: 2562.2939453125, Acc: 42.25806451612903\n",
      "Testing VaDE... Epoch: 111, Loss: 42.680277824401855, Acc: 43.61270111386139\n",
      "Training VaDE... Epoch: 112, Loss: 2565.1160888671875, Acc: 39.03225806451613\n",
      "Testing VaDE... Epoch: 112, Loss: 42.80706214904785, Acc: 41.95931311881188\n",
      "Training VaDE... Epoch: 113, Loss: 2567.2843017578125, Acc: 43.225806451612904\n",
      "Testing VaDE... Epoch: 113, Loss: 42.84471797943115, Acc: 43.37871287128713\n",
      "Training VaDE... Epoch: 114, Loss: 2561.0894775390625, Acc: 41.29032258064516\n",
      "Testing VaDE... Epoch: 114, Loss: 43.110740661621094, Acc: 40.57858910891089\n",
      "Training VaDE... Epoch: 115, Loss: 2569.571533203125, Acc: 39.67741935483871\n",
      "Testing VaDE... Epoch: 115, Loss: 43.35301113128662, Acc: 40.617264851485146\n",
      "Training VaDE... Epoch: 116, Loss: 2567.5318603515625, Acc: 41.29032258064516\n",
      "Testing VaDE... Epoch: 116, Loss: 42.85691833496094, Acc: 39.74512685643565\n",
      "Training VaDE... Epoch: 117, Loss: 2558.331787109375, Acc: 43.225806451612904\n",
      "Testing VaDE... Epoch: 117, Loss: 43.67864990234375, Acc: 38.28705136138614\n",
      "Training VaDE... Epoch: 118, Loss: 2557.759765625, Acc: 39.03225806451613\n",
      "Testing VaDE... Epoch: 118, Loss: 43.1724967956543, Acc: 40.68301361386139\n",
      "Training VaDE... Epoch: 119, Loss: 2557.9815673828125, Acc: 38.387096774193544\n",
      "Testing VaDE... Epoch: 119, Loss: 43.43082809448242, Acc: 38.911664603960396\n",
      "Training VaDE... Epoch: 120, Loss: 2562.7132568359375, Acc: 40.32258064516129\n",
      "Testing VaDE... Epoch: 120, Loss: 43.713595390319824, Acc: 40.87832611386139\n",
      "Training VaDE... Epoch: 121, Loss: 2548.3424072265625, Acc: 40.32258064516129\n",
      "Testing VaDE... Epoch: 121, Loss: 43.68135738372803, Acc: 39.0025525990099\n",
      "Training VaDE... Epoch: 122, Loss: 2551.932373046875, Acc: 36.12903225806451\n",
      "Testing VaDE... Epoch: 122, Loss: 43.79395294189453, Acc: 39.60202660891089\n",
      "Training VaDE... Epoch: 123, Loss: 2563.610595703125, Acc: 39.67741935483871\n",
      "Testing VaDE... Epoch: 123, Loss: 43.980716705322266, Acc: 39.445389851485146\n",
      "Training VaDE... Epoch: 124, Loss: 2551.341552734375, Acc: 41.935483870967744\n",
      "Testing VaDE... Epoch: 124, Loss: 43.786927223205566, Acc: 39.01608910891089\n",
      "Training VaDE... Epoch: 125, Loss: 2553.7410888671875, Acc: 40.0\n",
      "Testing VaDE... Epoch: 125, Loss: 44.096506118774414, Acc: 39.94043935643565\n",
      "Training VaDE... Epoch: 126, Loss: 2562.2879638671875, Acc: 38.70967741935484\n",
      "Testing VaDE... Epoch: 126, Loss: 43.89590930938721, Acc: 39.35450185643565\n",
      "Training VaDE... Epoch: 127, Loss: 2554.9598388671875, Acc: 38.70967741935484\n",
      "Testing VaDE... Epoch: 127, Loss: 43.55825901031494, Acc: 39.692914603960396\n",
      "Training VaDE... Epoch: 128, Loss: 2548.2452392578125, Acc: 36.45161290322581\n",
      "Testing VaDE... Epoch: 128, Loss: 44.03030300140381, Acc: 38.521039603960396\n",
      "Training VaDE... Epoch: 129, Loss: 2551.1192626953125, Acc: 41.935483870967744\n",
      "Testing VaDE... Epoch: 129, Loss: 44.56409549713135, Acc: 37.25827660891089\n",
      "Training VaDE... Epoch: 130, Loss: 2549.591552734375, Acc: 39.03225806451613\n",
      "Testing VaDE... Epoch: 130, Loss: 44.45589637756348, Acc: 40.13575185643565\n",
      "Training VaDE... Epoch: 131, Loss: 2546.886962890625, Acc: 40.64516129032258\n",
      "Testing VaDE... Epoch: 131, Loss: 44.87766361236572, Acc: 36.320389851485146\n",
      "Training VaDE... Epoch: 132, Loss: 2545.6759033203125, Acc: 40.0\n",
      "Testing VaDE... Epoch: 132, Loss: 44.640764236450195, Acc: 36.7496905940594\n",
      "Training VaDE... Epoch: 133, Loss: 2537.6632080078125, Acc: 37.74193548387097\n",
      "Testing VaDE... Epoch: 133, Loss: 44.527281761169434, Acc: 37.70111386138614\n",
      "Training VaDE... Epoch: 134, Loss: 2541.372314453125, Acc: 38.387096774193544\n",
      "Testing VaDE... Epoch: 134, Loss: 44.59301280975342, Acc: 37.84421410891089\n",
      "Training VaDE... Epoch: 135, Loss: 2540.608154296875, Acc: 37.096774193548384\n",
      "Testing VaDE... Epoch: 135, Loss: 44.87504291534424, Acc: 36.320389851485146\n",
      "Training VaDE... Epoch: 136, Loss: 2551.3782958984375, Acc: 40.64516129032258\n",
      "Testing VaDE... Epoch: 136, Loss: 44.887311935424805, Acc: 37.349164603960396\n",
      "Training VaDE... Epoch: 137, Loss: 2535.8045654296875, Acc: 37.41935483870968\n",
      "Testing VaDE... Epoch: 137, Loss: 44.83829307556152, Acc: 37.98731435643565\n",
      "Training VaDE... Epoch: 138, Loss: 2526.80078125, Acc: 34.83870967741935\n",
      "Testing VaDE... Epoch: 138, Loss: 45.229713439941406, Acc: 37.739789603960396\n",
      "Training VaDE... Epoch: 139, Loss: 2544.4342041015625, Acc: 36.774193548387096\n",
      "Testing VaDE... Epoch: 139, Loss: 44.554091453552246, Acc: 38.521039603960396\n",
      "Training VaDE... Epoch: 140, Loss: 2532.2880859375, Acc: 35.16129032258065\n",
      "Testing VaDE... Epoch: 140, Loss: 45.41987323760986, Acc: 36.567914603960396\n",
      "Training VaDE... Epoch: 141, Loss: 2534.630859375, Acc: 38.064516129032256\n",
      "Testing VaDE... Epoch: 141, Loss: 44.773406982421875, Acc: 37.38784034653465\n",
      "Training VaDE... Epoch: 142, Loss: 2539.5050048828125, Acc: 38.064516129032256\n",
      "Testing VaDE... Epoch: 142, Loss: 44.98266410827637, Acc: 35.66870358910891\n",
      "Training VaDE... Epoch: 143, Loss: 2527.0543212890625, Acc: 35.80645161290323\n",
      "Testing VaDE... Epoch: 143, Loss: 45.402414321899414, Acc: 36.8541150990099\n",
      "Training VaDE... Epoch: 144, Loss: 2537.19091796875, Acc: 36.45161290322581\n",
      "Testing VaDE... Epoch: 144, Loss: 45.50644111633301, Acc: 34.9009900990099\n",
      "Training VaDE... Epoch: 145, Loss: 2533.8148193359375, Acc: 38.387096774193544\n",
      "Testing VaDE... Epoch: 145, Loss: 45.6307430267334, Acc: 34.84877784653465\n",
      "Training VaDE... Epoch: 146, Loss: 2527.023681640625, Acc: 38.387096774193544\n",
      "Testing VaDE... Epoch: 146, Loss: 45.58069133758545, Acc: 36.0728650990099\n",
      "Training VaDE... Epoch: 147, Loss: 2525.3489990234375, Acc: 37.096774193548384\n",
      "Testing VaDE... Epoch: 147, Loss: 45.512959480285645, Acc: 35.82534034653465\n",
      "Training VaDE... Epoch: 148, Loss: 2535.7103271484375, Acc: 39.67741935483871\n",
      "Testing VaDE... Epoch: 148, Loss: 45.901519775390625, Acc: 36.593053836633665\n",
      "Training VaDE... Epoch: 149, Loss: 2535.7034912109375, Acc: 36.774193548387096\n",
      "Testing VaDE... Epoch: 149, Loss: 45.99348449707031, Acc: 34.88745358910891\n",
      "Training VaDE... Epoch: 150, Loss: 2542.498291015625, Acc: 34.83870967741935\n",
      "Testing VaDE... Epoch: 150, Loss: 45.5888032913208, Acc: 35.759591584158414\n",
      "Training VaDE... Epoch: 151, Loss: 2531.9248046875, Acc: 34.516129032258064\n",
      "Testing VaDE... Epoch: 151, Loss: 45.76252746582031, Acc: 35.7731280940594\n",
      "Training VaDE... Epoch: 152, Loss: 2527.6024169921875, Acc: 36.45161290322581\n",
      "Testing VaDE... Epoch: 152, Loss: 46.11465930938721, Acc: 35.23940284653465\n",
      "Training VaDE... Epoch: 153, Loss: 2539.9478759765625, Acc: 37.74193548387097\n",
      "Testing VaDE... Epoch: 153, Loss: 45.876298904418945, Acc: 35.27807858910891\n",
      "Training VaDE... Epoch: 154, Loss: 2521.343994140625, Acc: 35.16129032258065\n",
      "Testing VaDE... Epoch: 154, Loss: 46.05846691131592, Acc: 32.98654084158416\n",
      "Training VaDE... Epoch: 155, Loss: 2531.782958984375, Acc: 34.193548387096776\n",
      "Testing VaDE... Epoch: 155, Loss: 46.19440460205078, Acc: 35.7731280940594\n",
      "Training VaDE... Epoch: 156, Loss: 2532.599853515625, Acc: 34.516129032258064\n",
      "Testing VaDE... Epoch: 156, Loss: 46.19724941253662, Acc: 35.6822400990099\n",
      "Training VaDE... Epoch: 157, Loss: 2522.159912109375, Acc: 36.774193548387096\n",
      "Testing VaDE... Epoch: 157, Loss: 46.5035343170166, Acc: 34.639928836633665\n",
      "Training VaDE... Epoch: 158, Loss: 2519.0040283203125, Acc: 34.83870967741935\n",
      "Testing VaDE... Epoch: 158, Loss: 45.96106719970703, Acc: 36.05932858910891\n",
      "Training VaDE... Epoch: 159, Loss: 2531.499755859375, Acc: 37.41935483870968\n",
      "Testing VaDE... Epoch: 159, Loss: 46.400156021118164, Acc: 34.953202351485146\n",
      "Training VaDE... Epoch: 160, Loss: 2525.2606201171875, Acc: 38.70967741935484\n",
      "Testing VaDE... Epoch: 160, Loss: 47.1304817199707, Acc: 32.296178836633665\n",
      "Training VaDE... Epoch: 161, Loss: 2532.5191650390625, Acc: 40.96774193548387\n",
      "Testing VaDE... Epoch: 161, Loss: 46.62895393371582, Acc: 33.6246905940594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VaDE... Epoch: 162, Loss: 2521.3897705078125, Acc: 34.516129032258064\n",
      "Testing VaDE... Epoch: 162, Loss: 47.03949546813965, Acc: 34.35372834158416\n",
      "Training VaDE... Epoch: 163, Loss: 2528.0032958984375, Acc: 35.16129032258065\n",
      "Testing VaDE... Epoch: 163, Loss: 46.8110237121582, Acc: 33.220529084158414\n",
      "Training VaDE... Epoch: 164, Loss: 2525.6617431640625, Acc: 36.12903225806451\n",
      "Testing VaDE... Epoch: 164, Loss: 46.7675666809082, Acc: 33.32495358910891\n",
      "Training VaDE... Epoch: 165, Loss: 2522.4698486328125, Acc: 34.193548387096776\n",
      "Testing VaDE... Epoch: 165, Loss: 46.938920974731445, Acc: 32.686803836633665\n",
      "Training VaDE... Epoch: 166, Loss: 2515.173095703125, Acc: 35.483870967741936\n",
      "Testing VaDE... Epoch: 166, Loss: 46.9022331237793, Acc: 33.57247834158416\n",
      "Training VaDE... Epoch: 167, Loss: 2519.9840087890625, Acc: 32.903225806451616\n",
      "Testing VaDE... Epoch: 167, Loss: 47.05932140350342, Acc: 34.45815284653465\n",
      "Training VaDE... Epoch: 168, Loss: 2523.195068359375, Acc: 35.80645161290323\n",
      "Testing VaDE... Epoch: 168, Loss: 47.05984306335449, Acc: 35.86401608910891\n",
      "Training VaDE... Epoch: 169, Loss: 2525.2939453125, Acc: 35.80645161290323\n",
      "Testing VaDE... Epoch: 169, Loss: 46.94538402557373, Acc: 32.686803836633665\n",
      "Training VaDE... Epoch: 170, Loss: 2512.361083984375, Acc: 33.87096774193548\n",
      "Testing VaDE... Epoch: 170, Loss: 47.10056018829346, Acc: 33.57247834158416\n",
      "Training VaDE... Epoch: 171, Loss: 2513.459228515625, Acc: 30.32258064516129\n",
      "Testing VaDE... Epoch: 171, Loss: 47.30395793914795, Acc: 32.296178836633665\n",
      "Training VaDE... Epoch: 172, Loss: 2509.1036376953125, Acc: 36.12903225806451\n",
      "Testing VaDE... Epoch: 172, Loss: 47.085853576660156, Acc: 31.99644183168317\n",
      "Training VaDE... Epoch: 173, Loss: 2517.5806884765625, Acc: 33.225806451612904\n",
      "Testing VaDE... Epoch: 173, Loss: 46.96267795562744, Acc: 35.13497834158416\n",
      "Training VaDE... Epoch: 174, Loss: 2518.64697265625, Acc: 35.80645161290323\n",
      "Testing VaDE... Epoch: 174, Loss: 47.045538902282715, Acc: 34.001779084158414\n",
      "Training VaDE... Epoch: 175, Loss: 2514.072998046875, Acc: 33.225806451612904\n",
      "Testing VaDE... Epoch: 175, Loss: 46.79836845397949, Acc: 33.663366336633665\n",
      "Training VaDE... Epoch: 176, Loss: 2518.84521484375, Acc: 33.5483870967742\n",
      "Testing VaDE... Epoch: 176, Loss: 47.11386299133301, Acc: 34.1197400990099\n",
      "Training VaDE... Epoch: 177, Loss: 2518.9249267578125, Acc: 32.903225806451616\n",
      "Testing VaDE... Epoch: 177, Loss: 47.01040458679199, Acc: 31.267404084158414\n",
      "Training VaDE... Epoch: 178, Loss: 2525.30712890625, Acc: 34.193548387096776\n",
      "Testing VaDE... Epoch: 178, Loss: 47.78189277648926, Acc: 33.025216584158414\n",
      "Training VaDE... Epoch: 179, Loss: 2518.21923828125, Acc: 33.225806451612904\n",
      "Testing VaDE... Epoch: 179, Loss: 47.25858116149902, Acc: 34.53550433168317\n",
      "Training VaDE... Epoch: 180, Loss: 2522.4808349609375, Acc: 32.903225806451616\n",
      "Testing VaDE... Epoch: 180, Loss: 47.087496757507324, Acc: 32.03511757425743\n",
      "Training VaDE... Epoch: 181, Loss: 2520.4896240234375, Acc: 33.87096774193548\n",
      "Testing VaDE... Epoch: 181, Loss: 47.477468490600586, Acc: 32.54370358910891\n",
      "Training VaDE... Epoch: 182, Loss: 2524.185546875, Acc: 33.225806451612904\n",
      "Testing VaDE... Epoch: 182, Loss: 47.883545875549316, Acc: 31.058555074257427\n",
      "Training VaDE... Epoch: 183, Loss: 2511.0408935546875, Acc: 34.193548387096776\n",
      "Testing VaDE... Epoch: 183, Loss: 47.54248237609863, Acc: 31.80112933168317\n",
      "Training VaDE... Epoch: 184, Loss: 2506.2213134765625, Acc: 30.967741935483872\n",
      "Testing VaDE... Epoch: 184, Loss: 47.81367015838623, Acc: 32.40060334158416\n",
      "Training VaDE... Epoch: 185, Loss: 2512.133544921875, Acc: 34.516129032258064\n",
      "Testing VaDE... Epoch: 185, Loss: 47.645134925842285, Acc: 31.319616336633665\n",
      "Training VaDE... Epoch: 186, Loss: 2511.9508056640625, Acc: 32.58064516129032\n",
      "Testing VaDE... Epoch: 186, Loss: 47.3175687789917, Acc: 32.686803836633665\n",
      "Training VaDE... Epoch: 187, Loss: 2518.3104248046875, Acc: 34.193548387096776\n",
      "Testing VaDE... Epoch: 187, Loss: 47.59752559661865, Acc: 30.82456683168317\n",
      "Training VaDE... Epoch: 188, Loss: 2512.115966796875, Acc: 36.12903225806451\n",
      "Testing VaDE... Epoch: 188, Loss: 47.883928298950195, Acc: 29.01454207920792\n",
      "Training VaDE... Epoch: 189, Loss: 2508.729248046875, Acc: 33.225806451612904\n",
      "Testing VaDE... Epoch: 189, Loss: 47.72452259063721, Acc: 30.96766707920792\n",
      "Training VaDE... Epoch: 190, Loss: 2511.0484619140625, Acc: 36.45161290322581\n",
      "Testing VaDE... Epoch: 190, Loss: 47.95975971221924, Acc: 30.62925433168317\n",
      "Training VaDE... Epoch: 191, Loss: 2507.143798828125, Acc: 31.61290322580645\n",
      "Testing VaDE... Epoch: 191, Loss: 47.80649185180664, Acc: 31.21519183168317\n"
     ]
    }
   ],
   "source": [
    "vade.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 10\n",
    "model = vade.VaDE\n",
    "z, y = get_latent_space(dataloader_test, z_dim, model, device, vade.feature_extractor)\n",
    "z, y = z.cpu(), y.cpu()\n",
    "z_embedded = TSNE(n_components=2).fit_transform(z.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(z_embedded, y, classes, args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.array(vade.acc)\n",
    "acc_t = np.array(vade.acc_t)\n",
    "rec = np.array(vade.rec)\n",
    "rec_t = np.array(vade.rec_t)\n",
    "dkl = np.array(vade.dkl)\n",
    "dkl_t = np.array(vade.dkl_t)\n",
    "\n",
    "def plot_loss(values, values_t, metric, dataset):\n",
    "    plt.plot(np.arange(len(values)), values, c='k', label='train')\n",
    "    plt.plot(np.arange(len(values_t)), values_t, c='b', label='test')\n",
    "    plt.title('VaDE {}'.format(metric))\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('weights/vade_{}_{}_ss'.format(metric, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(acc, acc_t, 'Accuracy', args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(rec, rec_t, 'Reconstruction', args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(dkl[2:], dkl_t[2:], 'DKL', args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
