{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "from preprocess import get_mnist, get_webcam\n",
    "from train import TrainerVaDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size = 128\n",
    "    dataset = 'mnist'\n",
    "    n_shots = 1\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    \n",
    "args = Args() # Parsing all the arguments for the training\n",
    "if args.dataset == 'mnist':\n",
    "    dataloader_sup, dataloader_unsup, dataloader_test = get_mnist(args)\n",
    "    n_classes = 10\n",
    "else:\n",
    "    dataloader_sup, dataloader_unsup, dataloader_test = get_webcam(args)\n",
    "    n_classes = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == 'webcam':\n",
    "    from models_office import Autoencoder, feature_extractor, VaDE\n",
    "    VaDE = VaDE().to(device)\n",
    "    autoencoder = Autoencoder().to(device)\n",
    "    autoencoder.load_state_dict(torch.load('weights/autoencoder_parameters_webcam.pth.tar',\n",
    "                                    map_location=device)['state_dict'])\n",
    "    \n",
    "    checkpoint = torch.load('weights/feature_extractor_params.pth.tar',\n",
    "                             map_location=device)\n",
    "    feature_extractor = feature_extractor().to(device)\n",
    "    feature_extractor.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "elif args.dataset == 'mnist':\n",
    "    from models import Autoencoder, VaDE\n",
    "    VaDE = VaDE().to(device)\n",
    "    autoencoder = Autoencoder().to(device)\n",
    "    autoencoder.load_state_dict(torch.load('weights/autoencoder_parameters_mnist.pth.tar',\n",
    "                                    map_location=device)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_space(dataloader, z_dim, model, device, ftr_ext=None):\n",
    "    z = torch.zeros((1, z_dim)).float().to(device)\n",
    "    y = torch.zeros((1)).long().to(device)\n",
    "    with torch.no_grad():\n",
    "        for img, label in dataloader:\n",
    "            img, label = img.to(device).float(), label.to(device).long()\n",
    "            if ftr_ext is not None:\n",
    "                img = ftr_ext(img); img = img.detach()\n",
    "\n",
    "            z_l = model.encode(img)\n",
    "            y = torch.cat((y, label), dim=0)\n",
    "            z = torch.cat((z, z_l), dim=0)\n",
    "    return z[1:], y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=100,\n",
       "        means_init=None, n_components=10, n_init=1, precisions_init=None,\n",
       "        random_state=None, reg_covar=1e-06, tol=0.001, verbose=0,\n",
       "        verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_dim = 10\n",
    "\n",
    "z, _ = get_latent_space(dataloader_unsup, z_dim, autoencoder, device)\n",
    "z = z.cpu()\n",
    "gmm = GaussianMixture(n_components=n_classes, covariance_type='diag')\n",
    "gmm.fit(z.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 10\n",
    "z, y = get_latent_space(dataloader_sup, z_dim, autoencoder, device)\n",
    "z = z.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = z[np.argsort(y.cpu())]\n",
    "y = y[np.argsort(y.cpu())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = gmm.predict_proba(z.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_probas = []\n",
    "if args.n_shots>1:\n",
    "    for i in range(n_classes):\n",
    "        ixs = np.where(y.cpu()==i)\n",
    "        print(np.mean(probas[ixs], axis=0))\n",
    "        mean_probas.append(np.mean(probas[ixs], axis=0))\n",
    "    probas = np.array(mean_probas)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 has a top 1 prob of 0.7557658816968944 in index 3\n",
      "class 1 has a top 1 prob of 0.8884203770174495 in index 4\n",
      "class 2 has a top 1 prob of 0.9480040803017324 in index 5\n",
      "class 3 has a top 1 prob of 0.7680914726217992 in index 7\n",
      "class 4 has a top 1 prob of 0.694569128063975 in index 5\n",
      "class 4 has a top 2 prob of 0.22937955771153504 in index 2\n",
      "class 5 has a top 1 prob of 0.7824726577986791 in index 1\n",
      "class 6 has a top 1 prob of 0.8990052425637904 in index 8\n",
      "class 7 has a top 1 prob of 0.7202281136228281 in index 6\n",
      "class 8 has a top 1 prob of 0.9774442556105314 in index 0\n",
      "class 9 has a top 1 prob of 0.9935317281901505 in index 2\n",
      "class 9 has a top 2 prob of 0.006027929744999055 in index 6\n",
      "class 9 has a top 3 prob of 0.0001330048348857446 in index 7\n",
      "class 9 has a top 4 prob of 0.00012585562999016775 in index 3\n",
      "class 9 has a top 5 prob of 0.0001197818686216407 in index 5\n",
      "class 9 has a top 6 prob of 3.6687613794110633e-05 in index 0\n",
      "class 9 has a top 7 prob of 2.3413853821174337e-05 in index 8\n",
      "class 9 has a top 8 prob of 1.5903600984117126e-06 in index 1\n",
      "class 9 has a top 9 prob of 7.716718033444782e-09 in index 9\n",
      "[3, 4, 5, 7, 2, 1, 8, 6, 0, 9]\n"
     ]
    }
   ],
   "source": [
    "assignation = []\n",
    "possibilities = np.arange(n_classes)\n",
    "index = 0\n",
    "toselect = 1\n",
    "while len(possibilities)>0:\n",
    "    sorted_ = np.argsort(probas[index])\n",
    "    max_ = sorted_[-toselect]\n",
    "    print('class {} has a top {} prob of {} in index {}'.format(index, toselect, probas[index][max_], max_))\n",
    "    if max_ in possibilities:\n",
    "        assignation.append(max_)\n",
    "        possibilities = np.setdiff1d(possibilities, max_)\n",
    "        index+=1\n",
    "        toselect=1\n",
    "    else:\n",
    "        toselect+=1\n",
    "\n",
    "print(assignation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint('Saving weights.')\\nstate_dict = autoencoder.state_dict()\\n\\nVaDE.load_state_dict(state_dict, strict=False)\\nVaDE.pi_prior.data = torch.from_numpy(gmm.weights_[assignation]\\n                                          ).float().to(device)\\nVaDE.mu_prior.data = torch.from_numpy(gmm.means_[assignation]\\n                                          ).float().to(device)\\nVaDE.log_var_prior.data = torch.log(torch.from_numpy(gmm.covariances_[assignation]\\n                                        )).float().to(device)\\ntorch.save(VaDE.state_dict(), 'weights/pretrained_parameters_{}.pth'.format(args.dataset))\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print('Saving weights.')\n",
    "state_dict = autoencoder.state_dict()\n",
    "\n",
    "VaDE.load_state_dict(state_dict, strict=False)\n",
    "VaDE.pi_prior.data = torch.from_numpy(gmm.weights_[assignation]\n",
    "                                          ).float().to(device)\n",
    "VaDE.mu_prior.data = torch.from_numpy(gmm.means_[assignation]\n",
    "                                          ).float().to(device)\n",
    "VaDE.log_var_prior.data = torch.log(torch.from_numpy(gmm.covariances_[assignation]\n",
    "                                        )).float().to(device)\n",
    "torch.save(VaDE.state_dict(), 'weights/pretrained_parameters_{}.pth'.format(args.dataset))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 5, 9, 0, 1, 2, 7, 3, 6, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(probas, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.51196284e-11, 5.77842629e-09, 2.23419953e-12, 7.55765882e-01,\n",
       "       2.07838035e-44, 5.24618197e-04, 2.56798625e-14, 5.95797379e-04,\n",
       "       4.43854928e-08, 2.43113653e-01])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.67202338e-12, 3.29614253e-11, 2.29379558e-01, 7.60512946e-02,\n",
       "       3.93501937e-35, 6.94569128e-01, 4.21843734e-09, 2.97154530e-09,\n",
       "       1.23684190e-08, 5.43901515e-16])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.75766209e-12, 6.42434183e-08, 2.23527836e-09, 5.19921139e-02,\n",
       "       2.09831709e-24, 9.48004080e-01, 2.18216338e-10, 2.45080829e-07,\n",
       "       3.35991252e-06, 1.34111296e-07])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
