{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "from preprocess import get_mnist, get_webcam\n",
    "from train import TrainerVaDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size = 128\n",
    "    lr = 1e-5\n",
    "    dataset = 'webcam'\n",
    "    pretrained_path = 'weights/pretrained_parameter.pth'\n",
    "    patience = 50\n",
    "    pretrain = True\n",
    "    epochs = 200\n",
    "    n_shots = 1\n",
    "    sup_mul = 0.9\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    \n",
    "args = Args() # Parsing all the arguments for the training\n",
    "if args.dataset == 'mnist':\n",
    "    dataloader_sup,  dataloader_unsup = get_mnist(args)\n",
    "    n_classes = 10\n",
    "else:\n",
    "    dataloader_sup,  dataloader_unsup = get_webcam(args)\n",
    "    n_classes = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vade = TrainerVaDE(args, device, dataloader_sup, dataloader_unsup, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == 'webcam':\n",
    "    classes = ['back_pack',\n",
    "                'bike',\n",
    "                'bike_helmet',\n",
    "                'bookcase',\n",
    "                'bottle',\n",
    "                'calculator',\n",
    "                'desk_chair',\n",
    "                'desk_lamp',\n",
    "                'desktop_computer',\n",
    "                'file_cabinet',\n",
    "                'headphones',\n",
    "                'keyboard',\n",
    "                'laptop_computer',\n",
    "                'letter_tray',\n",
    "                'mobile_phone',\n",
    "                'monitor',\n",
    "                'mouse',\n",
    "                'mug',\n",
    "                'paper_notebook',\n",
    "                'pen',\n",
    "                'phone',\n",
    "                'printer',\n",
    "                'projector',\n",
    "                'punchers',\n",
    "                'ring_binder',\n",
    "                'ruler',\n",
    "                'scissors',\n",
    "                'speaker',\n",
    "                'stapler',\n",
    "                'tape_dispenser',\n",
    "                'trash_can']\n",
    "else:\n",
    "    classes = ['0',\n",
    "               '1',\n",
    "               '2',\n",
    "               '3',\n",
    "               '4',\n",
    "               '5',\n",
    "               '6',\n",
    "               '7',\n",
    "               '8',\n",
    "               '9']\n",
    "\n",
    "\n",
    "def get_latent_space(dataloader, z_dim, model, device, ftr_ext=None):\n",
    "    z = torch.zeros((1, z_dim)).float().to(device)\n",
    "    y = torch.zeros((1)).long().to(device)\n",
    "    with torch.no_grad():\n",
    "        for img, label in dataloader:\n",
    "            img, label = img.to(device).float(), label.to(device).long()\n",
    "            if ftr_ext is not None:\n",
    "                img = ftr_ext(img); img = img.detach()\n",
    "\n",
    "            mu, log_var = model.encode(img)\n",
    "            z_l = model.reparameterize(mu, log_var)\n",
    "            y = torch.cat((y, label), dim=0)\n",
    "            z = torch.cat((z, z_l), dim=0)\n",
    "    return z[1:], y[1:]\n",
    "\n",
    "\n",
    "def plot_tsne(X_embedded, y, ticks):\n",
    "    f, ax1 = plt.subplots(1, 1, sharey=True, figsize=(15,5))\n",
    "\n",
    "    cmap = plt.get_cmap('jet', 31)\n",
    "\n",
    "\n",
    "    cax = ax1.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y.numpy(),\n",
    "                      s=15, cmap=cmap)\n",
    "\n",
    "    cbar = f.colorbar(cax, ticks=np.linspace(0,30,31))\n",
    "    cbar.ax.set_yticklabels(ticks)\n",
    "\n",
    "    ax1.xaxis.set_visible(False)\n",
    "    ax1.yaxis.set_visible(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VaDE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ComputeLosses' object has no attribute 'priors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-63127ce94a84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Pytorch-SS-VaDE/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training VaDE...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_VaDE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_VaDE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Pytorch-SS-VaDE/train.py\u001b[0m in \u001b[0;36mtrain_VaDE\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mx_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconst_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_div\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Pytorch-SS-VaDE/forward_step.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, mode, x_sup, y_sup, x_unsup)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0munsupervised_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreconst_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkl_div\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mreconst_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_div\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupervised_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0msupervised_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreconst_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkl_div\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msupervised_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munsupervised_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Pytorch-SS-VaDE/forward_step.py\u001b[0m in \u001b[0;36msupervised_loss\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mmeans_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_prior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mcovs_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_var_prior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mp_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi_prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ComputeLosses' object has no attribute 'priors'"
     ]
    }
   ],
   "source": [
    "vade.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 10\n",
    "ftr_ext = vade.feature_extractor\n",
    "model = vade.VaDE\n",
    "z, y = get_latent_space(dataloader, z_dim, model, device, ftr_ext)\n",
    "z, y = z.cpu(), y.cpu()\n",
    "z_embedded = TSNE(n_components=2).fit_transform(z.detach().numpy())\n",
    "plot_tsne(z_embedded, y, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
